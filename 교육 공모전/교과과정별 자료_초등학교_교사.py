import os
import time
import pandas as pd
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, NoSuchElementException

# â”€â”€â”€ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
SAVE_DIR   = r"D:\ê³µëª¨ì „ìë£Œ"
FILENAME   = "ì—ë“€ë„·_êµê³¼ê³¼ì •ë³„ìë£Œ_ì´ˆë“±í•™êµ.xlsx"
OUTPUT_XLS = os.path.join(SAVE_DIR, FILENAME)
URL        = "https://ai.edunet.net/sbjSrcData/list/398"

os.makedirs(SAVE_DIR, exist_ok=True)

driver = webdriver.Chrome()
wait   = WebDriverWait(driver, 5)  # ìµœëŒ€ 5ì´ˆ ëŒ€ê¸°

def get_total_pages():
    wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, "div.pagination_box")))
    try:
        driver.find_element(By.CSS_SELECTOR, "div.pagination_box a.btn_last").click()
        wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, "div.pagination_box a.current_page")))
    except NoSuchElementException:
        pass

    pag = driver.find_element(By.CSS_SELECTOR, "div.pagination_box")
    nums = [int(a.text) for a in pag.find_elements(By.TAG_NAME, "a") if a.text.strip().isdigit()]
    total = max(nums) if nums else 1

    try:
        driver.find_element(By.CSS_SELECTOR, "div.pagination_box a.btn_first").click()
        wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, "div.pagination_box a.current_page")))
    except NoSuchElementException:
        pass

    return total

def crawl_all():
    driver.get(URL)
    total_pages = get_total_pages()
    print(f"ğŸ”– ì „ì²´ {total_pages}í˜ì´ì§€ í¬ë¡¤ë§ ì‹œì‘")

    records = []
    current_page = 1

    while current_page <= total_pages:
        wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, "div.pagination_box")))
        pag = driver.find_element(By.CSS_SELECTOR, "div.pagination_box")
        num_links = sorted(
            [(int(a.text), a) for a in pag.find_elements(By.TAG_NAME, "a") if a.text.strip().isdigit()],
            key=lambda x: x[0]
        )

        for page_num, link in num_links:
            if page_num < current_page or page_num > total_pages:
                continue
            try:
                link.click()
            except:
                print(f"âš ï¸ [{page_num}] í´ë¦­ ì‹¤íŒ¨, ê±´ë„ˆëœë‹ˆë‹¤.")
                current_page = page_num + 1
                continue

            try:
                wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, "div.info_box")))
            except TimeoutException:
                print(f"âš ï¸ [{page_num}] ë¡œë”© íƒ€ì„ì•„ì›ƒ(5ì´ˆ), ìŠ¤í‚µí•©ë‹ˆë‹¤.")
                current_page = page_num + 1
                continue

            print(f"â¡ï¸ [{page_num}/{total_pages}] ìˆ˜ì§‘ ì¤‘â€¦")
            info_boxes = driver.find_elements(By.CSS_SELECTOR, "div.info_box")
            for box in info_boxes:
                try:
                    title = box.find_element(By.CSS_SELECTOR, "p.title").text.strip()
                except:
                    title = ""
                try:
                    date = box.find_element(
                        By.CSS_SELECTOR,
                        "ul.option_box.date > li:nth-child(1) > strong"
                    ).text.strip()
                except:
                    date = ""
                # ì—¬ê¸°ì— 'êµì‚¬' ì»¬ëŸ¼ì„ ì¶”ê°€
                if title or date:
                    records.append({
                        "êµì‚¬": "êµì‚¬",
                        "ì±…ì œëª©": title,
                        "ë‚ ì§œ": date
                    })

            current_page = page_num + 1

        if current_page <= total_pages:
            try:
                prev_page = int(pag.find_element(By.CSS_SELECTOR, "a.current_page").text.strip())
            except:
                prev_page = None
            try:
                driver.find_element(By.CSS_SELECTOR, "div.pagination_box a.btn_next").click()
                time.sleep(3)
                if prev_page is not None:
                    expected = prev_page + len(num_links)
                    wait.until(EC.text_to_be_present_in_element(
                        (By.CSS_SELECTOR, "div.pagination_box a.current_page"),
                        str(expected)
                    ))
            except:
                print("âš ï¸ ë‹¤ìŒ ê·¸ë£¹ ì „í™˜ ëŒ€ê¸° ì‹¤íŒ¨, ì´ì–´ì„œ ì§„í–‰í•©ë‹ˆë‹¤.")

    driver.quit()

    # DataFrame ìƒì„± ì‹œ ì»¬ëŸ¼ ìˆœì„œ ì§€ì •
    df = pd.DataFrame(records, columns=["êµì‚¬", "ì±…ì œëª©", "ë‚ ì§œ"])
    df.to_excel(OUTPUT_XLS, index=False)
    print(f"âœ… í¬ë¡¤ë§ ì™„ë£Œ! íŒŒì¼ ì €ì¥: {OUTPUT_XLS}")

if __name__ == "__main__":
    crawl_all()
