import os
import time
import pandas as pd
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, NoSuchElementException

# â”€â”€â”€ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
SAVE_DIR   = r"D:\ê³µëª¨ì „ìë£Œ"
FILENAME   = "ì—ë“€ë„·_êµê³¼ê³¼ì •ë³„ìë£Œ_ì´ˆë“±í•™êµ.xlsx"
OUTPUT_XLS = os.path.join(SAVE_DIR, FILENAME)
URL        = "https://ai.edunet.net/sbjSrcData/list/398"

os.makedirs(SAVE_DIR, exist_ok=True)
driver = webdriver.Chrome()
wait   = WebDriverWait(driver, 5)      # ìš”ì†Œ ë¡œë”© ìµœëŒ€ 5ì´ˆ ëŒ€ê¸°

def click_filter(tab_name):
    """â€˜ì „ì²´â€™ ëŒ€ì‹  êµì‚¬/í•™ìƒ íƒ­ í´ë¦­ í›„ ë¡œë”© ëŒ€ê¸°"""
    try:
        btn = wait.until(EC.element_to_be_clickable(
            (By.XPATH, f"//ul[contains(@class,'filter_tab_number')]//li[normalize-space(text())='{tab_name}']")
        ))
        btn.click()
        # í•„í„° ì ìš© í›„ ì²« info_box í•˜ë‚˜ ëœ° ë•Œê¹Œì§€ ëŒ€ê¸°
        wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, "div.info_box")))
    except Exception:
        print(f"âš ï¸ í•„í„° â€˜{tab_name}â€™ í´ë¦­ ì‹¤íŒ¨")

def get_total_pages():
    """í˜„ì¬ í•„í„° ìƒíƒœì—ì„œ ì´ í˜ì´ì§€ ìˆ˜ êµ¬í•˜ê¸°"""
    wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, "div.pagination_box")))
    # ë§ˆì§€ë§‰ ê·¸ë£¹ìœ¼ë¡œ ì´ë™
    try:
        driver.find_element(By.CSS_SELECTOR, "div.pagination_box a.btn_last").click()
        wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, "div.pagination_box a.current_page")))
    except NoSuchElementException:
        pass
    pag = driver.find_element(By.CSS_SELECTOR, "div.pagination_box")
    nums = [int(a.text) for a in pag.find_elements(By.TAG_NAME, "a") if a.text.strip().isdigit()]
    total = max(nums) if nums else 1
    # ì²« í˜ì´ì§€ë¡œ ë³µê·€
    try:
        driver.find_element(By.CSS_SELECTOR, "div.pagination_box a.btn_first").click()
        wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, "div.pagination_box a.current_page")))
    except NoSuchElementException:
        pass
    return total

def crawl_for(tab_name, records):
    """ì£¼ì–´ì§„ íƒ­(êµì‚¬/í•™ìƒ) ì•„ë˜ ì „ì²´ í˜ì´ì§€ í¬ë¡¤ë§"""
    driver.get(URL)
    click_filter(tab_name)
    total_pages = get_total_pages()
    print(f"ğŸ”– [{tab_name}] ì „ì²´ {total_pages}í˜ì´ì§€ í¬ë¡¤ë§ ì‹œì‘")

    current = 1
    while current <= total_pages:
        # pagination ë¡œë“œ ëŒ€ê¸°
        wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, "div.pagination_box")))
        pag = driver.find_element(By.CSS_SELECTOR, "div.pagination_box")
        # ìˆ«ì ë§í¬ë§Œ í•„í„° & ì •ë ¬
        links = sorted(
            [(int(a.text), a) for a in pag.find_elements(By.TAG_NAME, "a")
             if a.text.strip().isdigit()],
            key=lambda x: x[0]
        )
        for page_num, link in links:
            if page_num < current or page_num > total_pages:
                continue
            try:
                link.click()
            except:
                print(f"âš ï¸ [{tab_name} {page_num}] í´ë¦­ ì‹¤íŒ¨, ìŠ¤í‚µ")
                current = page_num + 1
                continue

            # info_box ë“±ì¥ ëŒ€ê¸°
            try:
                wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, "div.info_box")))
            except TimeoutException:
                print(f"âš ï¸ [{tab_name} {page_num}] ë¡œë”© íƒ€ì„ì•„ì›ƒ, ìŠ¤í‚µ")
                current = page_num + 1
                continue

            print(f"â¡ï¸ [{tab_name} {page_num}/{total_pages}] ìˆ˜ì§‘ ì¤‘â€¦")
            for box in driver.find_elements(By.CSS_SELECTOR, "div.info_box"):
                try:
                    title = box.find_element(By.CSS_SELECTOR, "p.title").text.strip()
                except:
                    title = ""
                try:
                    date = box.find_element(
                        By.CSS_SELECTOR,
                        "ul.option_box.date > li:nth-child(1) > strong"
                    ).text.strip()
                except:
                    date = ""
                if title or date:
                    records.append({
                        "ëŒ€ìƒ": tab_name,
                        "ì±…ì œëª©": title,
                        "ë‚ ì§œ": date
                    })
            current = page_num + 1

        # ë‹¤ìŒ ê·¸ë£¹ìœ¼ë¡œ ë„˜ì–´ê°€ê¸°
        if current <= total_pages:
            try:
                prev = pag.find_element(By.CSS_SELECTOR, "a.current_page").text.strip()
                driver.find_element(By.CSS_SELECTOR, "div.pagination_box a.btn_next").click()
                time.sleep(3)
                # ë‹¤ìŒ ê·¸ë£¹ ì²« í˜ì´ì§€ ë²ˆí˜¸ í™•ì¸
                wait.until(EC.text_to_be_present_in_element(
                    (By.CSS_SELECTOR, "div.pagination_box a.current_page"),
                    str(int(prev) + len(links))
                ))
            except:
                print(f"âš ï¸ [{tab_name}] ë‹¤ìŒ ê·¸ë£¹ ì „í™˜ ì‹¤íŒ¨, ì¢…ë£Œ")
                break

def main():
    records = []
    for tab in ["êµì‚¬", "í•™ìƒ"]:
        crawl_for(tab, records)
    driver.quit()

    df = pd.DataFrame(records, columns=["ëŒ€ìƒ", "ì±…ì œëª©", "ë‚ ì§œ"])
    df.to_excel(OUTPUT_XLS, index=False)
    print(f"âœ… í¬ë¡¤ë§ ì™„ë£Œ! ì €ì¥ ê²½ë¡œ: {OUTPUT_XLS}")

if __name__ == "__main__":
    main()
